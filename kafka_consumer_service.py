#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆæœ¬çš„Kafkaæ¶ˆè´¹è€…æœåŠ¡ - è§£å†³åˆ†åŒºåˆ†é…å’Œæ¶ˆæ¯å¤„ç†é—®é¢˜
"""

import json
import logging
import time
import threading
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Any, List
from pathlib import Path

import mysql.connector
from mysql.connector import Error, pooling
from kafka import KafkaConsumer
import schedule

# åˆ›å»ºæ—¥å¿—ç›®å½•
log_dir = Path("/tmp/ai-pipeline-logs")
log_dir.mkdir(parents=True, exist_ok=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(log_dir / 'kafka_consumer_fixed.log')
    ]
)
logger = logging.getLogger(__name__)

# é…ç½® - ç®€åŒ–é…ç½®ï¼Œä½¿ç”¨å•ä¸ªæ¶ˆè´¹è€…
KAFKA_CONFIG = {
    'bootstrap_servers': 'localhost:9093',
    'group_id': 'ai_pipeline_consumer_group_fixed',
    'auto_offset_reset': 'earliest',
    'enable_auto_commit': True,
    'auto_commit_interval_ms': 5000,
    'max_poll_records': 50,
    'session_timeout_ms': 30000,
    'heartbeat_interval_ms': 10000
}

DB_CONFIG = {
    'host': 'localhost',
    'database': 'ai_pipeline',
    'user': 'aiuser',
    'password': 'aipassword',
    'charset': 'utf8mb4'
}

class SimpleDatabaseManager:
    def __init__(self):
        self.connection_pool = None
        self._init_connection_pool()
    
    def _init_connection_pool(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± """
        try:
            self.connection_pool = pooling.MySQLConnectionPool(
                pool_name="simple_ai_pipeline_pool",
                pool_size=20,
                **DB_CONFIG
            )
            logger.info("âœ… Database connection pool initialized successfully")
        except Error as e:
            logger.error(f"âŒ Failed to initialize connection pool: {e}")
            raise
    
    def save_message(self, message: Dict[str, Any]):
        """ä¿å­˜å•ä¸ªæ¶ˆæ¯åˆ°æ•°æ®åº“"""
        connection = None
        try:
            connection = self.connection_pool.get_connection()
            cursor = connection.cursor()
            
            # æ’å…¥AIæ¨¡å‹æ•°æ®
            insert_query = """
            INSERT INTO ai_model_data 
            (session_id, model_type, input_data, output_data, processing_time_ms, timestamp, status, metadata)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            cursor.execute(insert_query, (
                message['session_id'],
                message['model_type'],
                json.dumps(message.get('input_data', {}), ensure_ascii=False),
                json.dumps(message.get('output_data', {}), ensure_ascii=False),
                message.get('processing_time_ms', 0),
                datetime.fromisoformat(message['timestamp'].replace('Z', '+00:00')),
                message.get('status', 'success'),
                json.dumps(message.get('metadata', {}), ensure_ascii=False)
            ))
            
            # æ›´æ–°ä¼šè¯ä¿¡æ¯
            self._update_session(cursor, message)
            
            connection.commit()
            logger.info(f"âœ… Saved message for session: {message['session_id']}")
            return True
            
        except Error as e:
            logger.error(f"âŒ Error saving message: {e}")
            if connection:
                connection.rollback()
            return False
        finally:
            if connection and connection.is_connected():
                cursor.close()
                connection.close()
    
    def _update_session(self, cursor, message: Dict[str, Any]):
        """æ›´æ–°ä¼šè¯ä¿¡æ¯"""
        session_id = message['session_id']
        
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
        check_query = "SELECT session_id FROM sessions WHERE session_id = %s"
        cursor.execute(check_query, (session_id,))
        
        if cursor.fetchone():
            # æ›´æ–°ç°æœ‰ä¼šè¯
            update_query = """
            UPDATE sessions 
            SET updated_at = %s, 
                total_processing_time_ms = total_processing_time_ms + %s
            WHERE session_id = %s
            """
            cursor.execute(update_query, (
                datetime.fromisoformat(message['timestamp'].replace('Z', '+00:00')),
                message.get('processing_time_ms', 0),
                session_id
            ))
        else:
            # æ’å…¥æ–°ä¼šè¯
            insert_query = """
            INSERT INTO sessions (session_id, created_at, updated_at, total_processing_time_ms)
            VALUES (%s, %s, %s, %s)
            """
            cursor.execute(insert_query, (
                session_id,
                datetime.fromisoformat(message['timestamp'].replace('Z', '+00:00')),
                datetime.fromisoformat(message['timestamp'].replace('Z', '+00:00')),
                message.get('processing_time_ms', 0)
            ))

class SimpleKafkaConsumer:
    def __init__(self, db_manager: SimpleDatabaseManager):
        self.db_manager = db_manager
        self.consumer = None
        self.running = False
        self.thread_pool = ThreadPoolExecutor(max_workers=5)
    
    def start(self):
        """å¯åŠ¨æ¶ˆè´¹è€…"""
        try:
            self.consumer = KafkaConsumer(
                'ai_model_data',
                **KAFKA_CONFIG,
                value_deserializer=lambda m: json.loads(m.decode('utf-8'))
            )
            
            self.running = True
            logger.info("âœ… Kafka consumer started successfully")
            
            # å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯
            self._consume_messages()
            
        except Exception as e:
            logger.error(f"âŒ Failed to start Kafka consumer: {e}")
    
    def _consume_messages(self):
        """æ¶ˆè´¹æ¶ˆæ¯çš„ä¸»å¾ªç¯"""
        logger.info("ğŸ”„ Starting to consume messages...")
        processed_count = 0
        
        while self.running:
            try:
                # æ‹‰å–æ¶ˆæ¯
                message_batch = self.consumer.poll(timeout_ms=1000, max_records=10)
                
                if message_batch:
                    for topic_partition, messages in message_batch.items():
                        logger.info(f"ğŸ“¨ Received {len(messages)} messages from partition {topic_partition}")
                        
                        for message in messages:
                            processed_count += 1
                            logger.info(f"ğŸ” Processing message {processed_count}: {message.value.get('session_id')}")
                            
                            # åœ¨çº¿ç¨‹æ± ä¸­å¤„ç†æ¶ˆæ¯
                            # è¿”å›ä¸€ä¸ª Future å¯¹è±¡ã€‚è¿™ä¸ª Future å¯¹è±¡ä»£è¡¨ä¸€ä¸ªå¼‚æ­¥è®¡ç®—ï¼Œå®ƒä¼šåœ¨æœªæ¥æŸä¸ªæ—¶é—´ç‚¹å®Œæˆï¼Œå¹¶æŒæœ‰ä»»åŠ¡æ‰§è¡Œçš„ç»“æœæˆ–å¼‚å¸¸ã€‚
                            future = self.thread_pool.submit(self._process_single_message, message.value)
                            future.add_done_callback(self._handle_processing_result)
                
                # å®šæœŸæäº¤åç§»é‡
                self.consumer.commit_async()
                
            except Exception as e:
                logger.error(f"âŒ Error in consume loop: {e}")
                time.sleep(1)
    
    def _process_single_message(self, message: Dict[str, Any]):
        """å¤„ç†å•ä¸ªæ¶ˆæ¯"""
        try:
            success = self.db_manager.save_message(message)
            if success:
                logger.debug(f"âœ… Successfully processed message: {message.get('session_id')}")
            else:
                logger.error(f"âŒ Failed to process message: {message.get('session_id')}")
            return success
        except Exception as e:
            logger.error(f"âŒ Error processing message: {e}")
            return False
    
    def _handle_processing_result(self, future):
        """å¤„ç†å¤„ç†ç»“æœ"""
        try:
            success = future.result()
            if not success:
                logger.warning("âš ï¸ Message processing failed")
        except Exception as e:
            logger.error(f"âŒ Error in message processing result: {e}")
    
    def stop(self):
        """åœæ­¢æ¶ˆè´¹è€…"""
        self.running = False
        if self.consumer:
            self.consumer.close()
        self.thread_pool.shutdown(wait=True)
        logger.info("âœ… Kafka consumer stopped")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ Starting Kafka Consumer Service...")
    
    # ç­‰å¾…æœåŠ¡å°±ç»ª
    logger.info("â³ Waiting for services to be ready...")
    time.sleep(10)
    
    db_manager = None
    consumer = None
    
    try:
        # åˆå§‹åŒ–ç»„ä»¶
        db_manager = SimpleDatabaseManager()
        consumer = SimpleKafkaConsumer(db_manager)
        
        # å¯åŠ¨æ¶ˆè´¹è€…,å¾ªç¯è·å–kafkaæ¶ˆæ¯
        consumer.start()
        
    except KeyboardInterrupt:
        logger.info("Received interrupt signal, shutting down...")
    except Exception as e:
        logger.error(f"Error in main: {e}")
    finally:
        if consumer:
            consumer.stop()
        logger.info("âœ… Fixed Kafka Consumer Service shutdown complete")

if __name__ == "__main__":
    main()